{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "435c4049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import * \n",
    "from pyspark.sql.functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35209ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "908a7170",
   "metadata": {},
   "source": [
    "## Cars dataset \n",
    "cars#$day#$cumulative_distance\n",
    "car1#$day1#$50\n",
    "car1#$day2#$100\n",
    "car1#$day3#$200\n",
    "car2#$day1#$0\n",
    "car3#$day1#$0\n",
    "car3#$day2#$50\n",
    "car3#$day3#$50\n",
    "car3#$day4#$100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3416e558",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input dataset has multiple delimiter - (#$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31be0fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df = spark.read.csv(\"/user/itv007180/cars.txt\",header=\"true\",inferSchema=True,sep=\"#$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "242f03fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can use option \"sep\" - option to secify separator while reading a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d89dda2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-------------------+\n",
      "|cars| day|cumulative_distance|\n",
      "+----+----+-------------------+\n",
      "|car1|day1|               50.0|\n",
      "|car1|day2|              100.0|\n",
      "|car1|day3|              200.0|\n",
      "|car2|day1|                0.0|\n",
      "|car3|day1|                0.0|\n",
      "|car3|day2|               50.0|\n",
      "|car3|day3|               50.0|\n",
      "|car3|day4|              100.0|\n",
      "+----+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cars_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9fe50bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution 1 \n",
    "\n",
    "## Here i am using offset as 1 in lag function because i wanted to compare with just previous record AND 0 so that i can use in operation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34d730e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-------------------+--------------+\n",
      "|cars| day|cumulative_distance|daily_distance|\n",
      "+----+----+-------------------+--------------+\n",
      "|car1|day1|               50.0|          50.0|\n",
      "|car1|day2|              100.0|          50.0|\n",
      "|car1|day3|              200.0|         100.0|\n",
      "|car2|day1|                0.0|           0.0|\n",
      "|car3|day1|                0.0|           0.0|\n",
      "|car3|day2|               50.0|          50.0|\n",
      "|car3|day3|               50.0|           0.0|\n",
      "|car3|day4|              100.0|          50.0|\n",
      "+----+----+-------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mywindow = Window.partitionBy(\"cars\").orderBy(\"day\")\n",
    "cars_df.withColumn(\"daily_distance\",cars_df.cumulative_distance-lag(cars_df.cumulative_distance,1,0).over(mywindow)).orderBy(\"cars\",\"day\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a4f657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
